---
title: "CITS4009 Project - Exploratory Data Analysis and Predictive Modeling"
author: "Binghan CHEN(23965953)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

# Load necessary libraries
library(ggplot2)      # For data visualization
library(dplyr)        # For data manipulation
library(tidyverse)
library(tidyr)        # For tidying data
library(knitr)        # For creating tables in the report
library(factoextra)   # For visualizing clustering results and determining optimal clusters
library(cluster)      # For clustering algorithms like K-means
library(corrplot)     # For visualizing correlation matrices
library(caret)        # For splitting the data and evaluating models
library(pROC)         # For ROC curve and AUC calculation
library(car)          # For calculating Variance Inflation Factor (VIF)
library(lime)         # For model interpretation with LIME
library(rpart)
library(rpart.plot)
library(scales)
```

# **Introduction**

The objective of this project is to perform exploratory data analysis (EDA) and predictive modeling using the "Countries and Death Causes" dataset provided by the World Health Organisation (WHO). This dataset encompasses various health-related metrics for different countries over several years. Additionally, by integrating **GDP per Capita** data from the World Bank, we aim to examine the interplay between economic status and mortality rates. The primary goal is to uncover insights from the data and build predictive models to understand the factors influencing death rates. By analyzing these health and socioeconomic factors, we aim to identify key determinants of health outcomes and provide actionable recommendations for improving public health policies.

# **Section 1: Exploratory Study of the Data**

## **1.1. Data Overview**

### **1.1.1. Loading the Dataset**

```{r load-data, cache=TRUE}
# Read the dataset 
data <- read.csv("Countries_and_Death_Causes.csv", stringsAsFactors = FALSE)

# Display the first few rows of the dataset
head(data)

```

The dataset includes 6,840 observations spanning from 1990 to 2019, covering various health and socio-economic indicators for different countries. Initial observations reveal a diverse range of metrics such as air pollution levels, blood pressure, dietary habits, and child health indicators, providing a comprehensive foundation for analysis.

### **1.1.2. Understanding the Structure of the Data**

```{r}
str(data)
```

The data frame consists of 31 variables, both categorical (e.g., `Entity`, `Code`) and numerical (e.g., `Outdoor.air.pollution`, `High.systolic.blood.pressure`). This structure allows for multifaceted analysis of health-related factors influencing mortality rates across countries and years.

### **1.1.3. Summary Statistics**

```{r}
summary(data)
```

Summary statistics highlight significant variability in key health indicators:

- **Outdoor Air Pollution:** Ranges widely from 0 to over 4.5 million, indicating diverse environmental conditions.
- **High Systolic Blood Pressure:** Values vary from 2 to over 10 million, reflecting differing health profiles.
- **Dietary Factors:** Median sodium intake is 969.5, with substantial values in whole grains and fruits consumption.
- **Lifestyle Indicators:** Moderate alochol use (median ~1,780) and significant smoking rates (median ~4,987) suggest prevalent lifestyle risks.
- **Child Health Metrics:** Median values for child wasting and stunting indicate ongoing nutritional challenges.

## **1.2. Data Cleaning**

### **1.2.1. Checking for Missing Values**

```{r miss-data, cache=TRUE}
# Function to count missing values in each column
count_missing <- function(df) {
  sapply(df, function(col) sum(is.na(col)))
}

nacounts <- count_missing(data) 
hasNA <- which(nacounts > 0) 
nacounts[hasNA]
```

The analysis for missing values across all columns indicated that there are no missing entries in the dataset. Each variable is fully populated, ensuring data completeness and eliminating the need for imputation or the removal of incomplete records in subsequent analyses.

### **1.2.2. Handling Data Anomalies**

To ensure the accuracy and reliability of our analysis, it is essential to identify and address anomalies in the dataset. Outliers can skew results and lead to misleading interpretations. We focused on the following key variables for anomaly detection and removal:

- **Outdoor Air Pollution**
- **High Systolic Blood Pressure**
- **Diet High in Sodium**
- **Smoking**
- **High Body Mass Index**

**Detecting and Removing Outliers**

We utilized the Interquartile Range (IQR) method to detect outliers in the selected variables. The IQR method is effective in identifying extreme values that lie beyond 1.5 times the IQR above the third quartile or below the first quartile.

```{r anomalies-data, cache=TRUE}
# Create a clean copy of the dataset
data_clean <- data

# List of numerical columns to check for anomalies
key_numeric_cols <- c("Outdoor.air.pollution", 
                      "High.systolic.blood.pressure", 
                      "Diet.high.in.sodium", 
                      "Smoking", 
                      "High.body.mass.index")

# Function to remove outliers based on IQR for a given column
remove_outliers <- function(df, column) {
  Q1 <- quantile(df[[column]], 0.25, na.rm = TRUE)
  Q3 <- quantile(df[[column]], 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  df_filtered <- df %>%
    filter(df[[column]] >= lower_bound & df[[column]] <= upper_bound)
  return(df_filtered)
}

# Iterate over each key column and remove outliers
for(col in key_numeric_cols){
  # Plot boxplot before removing outliers
  p_before <- ggplot(data_clean, aes_string(y = col)) +
    geom_boxplot(fill = "lightblue") +
    labs(title = paste("Boxplot of", col, "(Before Outlier Removal)"), y = col) +
    theme_minimal()
  
  print(p_before)
  
  # Remove outliers
  data_clean <- remove_outliers(data_clean, col)
  
  # Plot boxplot after removing outliers
  p_after <- ggplot(data_clean, aes_string(y = col)) +
    geom_boxplot(fill = "lightgreen") +
    labs(title = paste("Boxplot of", col, "(After Outlier Removal)"), y = col) +
    theme_minimal()
  
  print(p_after)
}
```

- **Outdoor Air Pollution:** The initial boxplot indicated extreme values for outdoor air pollution, with outliers exceeding 4 million. After removing these anomalies, the distribution became more uniform, reflecting typical pollution levels across regions.

- **High Systolic Blood Pressure:** Outliers in this variable showed abnormally high blood pressure readings, some above 200,000. Post-removal, the values were constrained to a more realistic range under 40,000, providing a clearer picture of general health trends.

- **Diet High in Sodium:** Initially, sodium consumption values spiked over 15,000, far exceeding normal dietary patterns. After filtering, the maximum value was brought below 3,000, offering a more accurate reflection of sodium consumption.

- **Smoking:** Countries with exceedingly high smoking rates caused outliers in this variable, which were removed to reveal a more typical distribution of global smoking behaviors under 10,000.

- **High Body Mass Index:** The boxplot showed extreme BMI values exceeding 20,000, which were removed to keep the data within a reasonable range (below 8,000), ensuring a valid analysis of BMI-related health trends.

**Summary of Data Cleaning**

By addressing outliers in these key health-related variables, we have cleaned the dataset to minimize the risk of skewed analysis. This ensures that the exploratory study and predictive modeling reflect realistic trends and patterns in the global health data.

### **1.2.3. Final Cleaned Dataset**
After addressing missing values and removing significant outliers, the dataset is now cleaned and ready for further exploratory analysis and predictive modeling. The removal of extreme outliers has ensured that the distributions of key health-related variables such as air pollution, blood pressure, sodium consumption, smoking rates, and BMI are more representative of typical global trends. This clean dataset offers a reliable foundation for uncovering meaningful insights and building predictive models.

```{r}
# Display the first few rows of the cleaned dataset
head(data_clean)
```

## **1.3. Visualisation**

### **1.3.1. Single Variable Visualisation**

We begin by exploring some key variables from the dataset to understand their distribution and general patterns. 

- **Outdoor Air Pollution**

A histogram shows the distribution of pollution levels, and a boxplot identifies outliers. This variable is critical for understanding environmental factors contributing to health outcomes.

```{r plot-Outdoor.air.pollution, cache=TRUE}
# Histogram
ggplot(data_clean, aes(x = Outdoor.air.pollution)) +
  geom_histogram(fill = "blue", bins = 30, color = "black") +
  labs(title = "Distribution of Outdoor Air Pollution",
       x = "Outdoor Air Pollution Levels",
       y = "Frequency")

# Boxplot
ggplot(data_clean, aes(y = Outdoor.air.pollution)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Boxplot of Outdoor Air Pollution")
```

**Histogram:** The distribution of outdoor air pollution shows a heavy skew to the right, with most countries having lower levels of air pollution. Only a small number of cases exhibit significantly higher pollution levels.

**Boxplot:** The boxplot shows a significant number of outliers on the higher end. This indicates that while most countries have moderate pollution levels, there are a few extreme cases with very high pollution.

- **High Systolic Blood Pressure**

We visualize the distribution of systolic blood pressure levels to identify typical ranges and extreme values.

```{r plot-High.systolic.blood.pressure, cache=TRUE}
# Histogram
ggplot(data_clean, aes(x = High.systolic.blood.pressure)) +
  geom_histogram(fill = "orange", bins = 30, color = "black") +
  labs(title = "Distribution of High Systolic Blood Pressure",
       x = "High Systolic Blood Pressure",
       y = "Frequency")

# Boxplot
ggplot(data_clean, aes(y = High.systolic.blood.pressure)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Boxplot of High Systolic Blood Pressure")
```

**Histogram:** This variable also has a right-skewed distribution, where the majority of countries have lower average systolic blood pressure levels. There is a noticeable long tail of higher blood pressure levels.

**Boxplot:** The presence of outliers in the boxplot indicates a small number of countries where the population's systolic blood pressure levels are much higher than the global average.

- **Smoking**

Here, we examine the distribution of smoking rates across countries, focusing on global smoking patterns.

```{r plot-Smoking, cache=TRUE}
# Histogram
ggplot(data_clean, aes(x = Smoking)) +
  geom_histogram(fill = "purple", bins = 30, color = "black") +
  labs(title = "Distribution of Smoking Rates",
       x = "Smoking Rate",
       y = "Frequency")

# Boxplot
ggplot(data_clean, aes(y = Smoking)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Boxplot of Smoking Rates")
```

**Histogram:** The smoking rates distribution is heavily skewed to the right, with the majority of countries having lower smoking rates. A few countries exhibit significantly higher rates, creating a long tail.

**Boxplot:** Similar to other variables, the boxplot shows several outliers indicating countries with extremely high smoking prevalence compared to the global trend.

- **Diet High in Sodium**

This visualization looks at sodium consumption patterns across countries, which is a major factor contributing to heart disease.

```{r plot-Diet.high.in.sodium, cache=TRUE}
# Histogram
ggplot(data_clean, aes(x = Diet.high.in.sodium)) +
  geom_histogram(fill = "red", bins = 30, color = "black") +
  labs(title = "Distribution of Diet High in Sodium",
       x = "High Sodium Diet",
       y = "Frequency")

# Boxplot
ggplot(data_clean, aes(y = Diet.high.in.sodium)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Boxplot of Diet High in Sodium")
```

**Histogram:** The distribution for a high-sodium diet shows that most countries have relatively low sodium intake. There are fewer countries with higher sodium consumption.

**Boxplot:** The boxplot also displays outliers, suggesting that some countries consume a notably higher amount of sodium than the average.

### **1.3.2. Multiple Variable Visualisation**

We will explore relationships between different variables to identify any potential correlations, trends, or interesting patterns. A common way to visualize these relationships is by using scatter plots, correlation heatmaps, or pair plots.

- **Outdoor Air Pollution vs. High Systolic Blood Pressure**

This could explore the relationship between environmental pollution and blood pressure levels, which could reflect the impact of pollution on public health.

- **Smoking Rates vs. High Systolic Blood Pressure**

We could examine if there's any visible trend between smoking rates and high blood pressure across different countries.

- **Diet High in Sodium vs. High Systolic Blood Pressure**

This explores the well-known relationship between sodium intake and high blood pressure, looking for trends in the data.

- **Smoking Rates vs. Diet High in Sodium**

Investigating whether countries with high smoking rates also have higher sodium consumption, which might reflect unhealthy lifestyle correlations.

```{r plot-multi-var, cache=TRUE}
# Multiple variable visualisation - Scatterplots

# 1. Outdoor Air Pollution vs. High Systolic Blood Pressure
ggplot(data_clean, aes(x = Outdoor.air.pollution, y = High.systolic.blood.pressure)) +
  geom_point(color = "blue", alpha = 0.6) +
  labs(title = "Outdoor Air Pollution vs High Systolic Blood Pressure", 
       x = "Outdoor Air Pollution", y = "High Systolic Blood Pressure") +
  theme_minimal()

# 2. Smoking Rates vs. High Systolic Blood Pressure
ggplot(data_clean, aes(x = Smoking, y = High.systolic.blood.pressure)) +
  geom_point(color = "purple", alpha = 0.6) +
  labs(title = "Smoking Rates vs High Systolic Blood Pressure", 
       x = "Smoking Rates", y = "High Systolic Blood Pressure") +
  theme_minimal()

# 3. Diet High in Sodium vs. High Systolic Blood Pressure
ggplot(data_clean, aes(x = Diet.high.in.sodium, y = High.systolic.blood.pressure)) +
  geom_point(color = "red", alpha = 0.6) +
  labs(title = "Diet High in Sodium vs High Systolic Blood Pressure", 
       x = "Diet High in Sodium", y = "High Systolic Blood Pressure") +
  theme_minimal()

# 4. Smoking Rates vs. Diet High in Sodium
ggplot(data_clean, aes(x = Smoking, y = Diet.high.in.sodium)) +
  geom_point(color = "green", alpha = 0.6) +
  labs(title = "Smoking Rates vs Diet High in Sodium", 
       x = "Smoking Rates", y = "Diet High in Sodium") +
  theme_minimal()
```

```{r plot-corr, fig.width=10, fig.height=10, cache=TRUE}
# 5. Correlation heatmap (if multiple variables are being explored at once)
numeric_vars <- data_clean[, sapply(data_clean, is.numeric)]
corr_matrix <- cor(numeric_vars, use = "complete.obs")
corrplot(corr_matrix, method = "color", tl.cex = 0.6, number.cex = 0.7, tl.col = "black", tl.srt = 45)
```

**Interpretation of Results**:

- **Outdoor Air Pollution vs. High Systolic Blood Pressure**

The scatter plot demonstrates a positive correlation between outdoor air pollution and high systolic blood pressure. As pollution levels increase, so do systolic blood pressure levels. This suggests that environmental factors like air quality may play a role in blood pressure-related health outcomes across different regions.

- **Smoking Rates vs. High Systolic Blood Pressure**

There is also a positive relationship between smoking rates and systolic blood pressure. Higher smoking rates correlate with higher blood pressure levels, reinforcing the well-known link between smoking and cardiovascular health risks.

- **Diet High in Sodium vs. High Systolic Blood Pressure**

This scatter plot highlights a strong positive correlation between high sodium diet and systolic blood pressure. As sodium intake increases, systolic blood pressure also rises significantly. This observation aligns with existing health research that high sodium intake contributes to hypertension.

- **Smoking Rates vs. Diet High in Sodium**

Interestingly, the relationship between smoking rates and sodium intake is less pronounced but still suggests that higher smoking prevalence might coincide with higher sodium consumption. This could point to broader lifestyle or dietary patterns in certain regions.

- **Correlation Heatmap**

The heatmap provides an overview of the correlations between all variables in the dataset. Darker colors represent stronger positive correlations, while lighter colors indicate weaker or negative relationships. Notably, high systolic blood pressure shows strong correlations with several lifestyle factors, including smoking and diet. Similarly, outdoor air pollution also correlates with multiple health outcomes.

### **1.3.3. Time Series Visualisation**

We aim to explore how key health metrics, such as outdoor air pollution, smoking rates, and high systolic blood pressure, have changed over time. Time series visualizations will allow us to identify trends, fluctuations, and patterns across different years.

- **Time Series of Outdoor Air Pollution Over the Years**

```{r plot-time-Outdoor.air.pollution, cache=TRUE}
ggplot(data_clean, aes(x = Year, y = Outdoor.air.pollution, color = Entity)) +
  geom_line(linewidth = 1, alpha = 0.7) +   
  theme_minimal() +
  labs(title = "Outdoor Air Pollution Over Time",
       x = "Year",
       y = "Outdoor Air Pollution Levels") +
  theme(legend.position = "none")
```

The time series plot for Outdoor Air Pollution shows varied trends among different countries. Some countries experienced a notable increase in outdoor air pollution over time, especially after 2000, while others remained relatively stable or even declined slightly. The visual differences across countries highlight the diverse environmental situations worldwide. This trend could suggest that some nations are more susceptible to rising air pollution due to factors like industrialization or lack of pollution control measures.

- **Time Series of High Systolic Blood Pressure Over the Years**

```{r plot-time-High.systolic.blood.pressure, cache=TRUE}
# Time Series for High Systolic Blood Pressure
ggplot(data_clean, aes(x = Year, y = High.systolic.blood.pressure, color = Entity)) +
  geom_line(size = 1, alpha = 0.7) +
  theme_minimal() +
  labs(title = "High Systolic Blood Pressure Over Time",
       x = "Year",
       y = "High Systolic Blood Pressure Levels") +
  theme(legend.position = "none")
```

For High Systolic Blood Pressure, the time series visualization reveals that, while most countries exhibit a consistent increase in blood pressure levels, there are fluctuations for certain countries. This increasing trend aligns with global health concerns regarding lifestyle-related diseases such as hypertension, which could be influenced by factors such as diet and physical inactivity. A few countries also show relatively higher levels of systolic blood pressure throughout the observed years.

- **Time Series of Smoking Rates Over the Years**

```{r plot-time-Smoking, cache=TRUE}
# Time Series for Smoking Rates
ggplot(data_clean, aes(x = Year, y = Smoking, color = Entity)) +
  geom_line(size = 1, alpha = 0.7) +
  theme_minimal() +
  labs(title = "Smoking Rates Over Time",
       x = "Year",
       y = "Smoking Rates") +
  theme(legend.position = "none")
```

The Smoking Rates Over Time plot shows a range of trends, with some countries witnessing steady increases in smoking rates, while others experience fluctuations or even a decline over time. The wide variation in smoking behaviors across countries could be due to factors such as public health initiatives, taxation on tobacco, or cultural practices. Despite some regions reducing smoking rates, many countries still show significantly high levels, which can have a direct impact on health-related issues, including high blood pressure and cardiovascular diseases.

# **Section 2: Predictive Modeling**

## **2.1. Problem Definition**

For this project, we aim to predict the **death rate** (high/low) for each country based on various health, socioeconomic, and environmental factors. The death rate serves as the response variable, which we will classify into two categories: **high** and **low** death rates. This binary classification will help to identify patterns and key factors contributing to death rates in different countries.

## **2.2. Data Preparation**

### **2.2.1. Response Variable**

We focus on creating a suitable response variable for the classification task. Given that the provided dataset (`Countries_and_Death_Causes`) does not directly contain death rates, we utilize additional data from the World Bank, specifically **total population** and **GDP per capita**. We aim to create a binary classification problem where countries are categorized based on mortality rates.

**a. Merging Datasets**:

We merge the `Countries_and_Death_Causes` dataset with the World Bank datasets, `data_population` (total population) and `data_GDP_per_Capita` (GDP per capita), by aligning the **country codes** and **years** in each dataset. This merged dataset will allow us to analyze health factors in relation to population size and economic conditions.

```{r merge-data, cache=TRUE}
# Load Population and GDP per Capita Data
population_df <- read_csv("Population_Data.csv")
gdp_df <- read_csv("GDP_per_Capita_Data.csv")

# Define a function to pivot data from wide to long
melt_data <- function(df, value_name) {
  df_long <- df %>%
    pivot_longer(
      cols = matches("^\\d{4}$"), # Select columns that are exactly four digits (e.g., 1960)
      names_to = "Year",
      values_to = value_name
    ) %>%
    mutate(
      Year = as.integer(Year)
    )
  return(df_long)
}

# Melt Population and GDP Data
population_long <- melt_data(population_df, "Population") %>%
  select(-'Indicator Name', -'Indicator Code') %>%
  drop_na(Population) %>%
  mutate(Population = as.numeric(Population))

gdp_long <- melt_data(gdp_df, "GDP_per_Capita") %>%
  select(-'Indicator Name', -'Indicator Code') %>%
  drop_na(GDP_per_Capita) %>%
  mutate(GDP_per_Capita = as.numeric(GDP_per_Capita))

# Ensure Year is integer in data_clean
data_clean <- data_clean %>%
  mutate(Year = as.integer(Year))

# Merge data_clean with Population Data
merged_df <- data_clean %>%
  left_join(population_long, by = c("Code" = "Country Code", "Year" = "Year"))

# Merge with GDP per Capita Data
merged_df <- merged_df %>%
  left_join(gdp_long, by = c("Code" = "Country Code", "Year" = "Year"))

# Remove rows with missing Population or GDP_per_Capita after merge
merged_df <- merged_df %>%
  drop_na(Population, GDP_per_Capita)

# Retain only rows where Country.Code has exactly three letters
merged_df <- merged_df %>%
  filter(str_length(Code) == 3)

# Identify valid Country Codes from population_long and gdp_long
valid_country_codes <- intersect(population_long$'Country Code', gdp_long$'Country Code')

# Filter merged_df to include only valid Country Codes
merged_df <- merged_df %>%
  filter(Code %in% valid_country_codes)

# Check for duplicate rows based on Country.Code and Year
duplicated_rows <- merged_df %>%
  group_by(Code, Year) %>%
  filter(n() > 1)

# Handle Duplicates
if(nrow(duplicated_rows) > 0){
  print("Duplicated Rows Found:")
  print(duplicated_rows)
  
  # Optionally, remove duplicates by keeping the first occurrence
  merged_df <- merged_df %>%
    distinct(Code, Year, .keep_all = TRUE)
  
  print("Duplicates have been removed by keeping the first occurrence.")
} else {
  print("No duplicate rows based on Country.Code and Year.")
}

# Verify specific entries (optional)
# Example: Check data for Albania in 1990
albania_1990 <- merged_df %>%
  filter(Code == "ALB", Year == 1990)

print(albania_1990)

# Confirmation message
print("Datasets merged successfully!")

```

**b. Mortality Proxy Calculation**:

To predict the death rate for each country, we construct a **Mortality Proxy** that aggregates various health-related and environmental risk factors. This proxy serves as an estimated measure of mortality risk, combining multiple indicators into a single, comprehensive metric. By normalizing the sum of these factors by the country's total population, we ensure that the proxy accounts for population size, facilitating meaningful comparisons across countries.

The formula for the Mortality Proxy is as follows:

$$
\small{
\text{Mortality Proxy} = \frac{\text{Outdoor Air Pollution} + \text{High Systolic Blood Pressure} + \text{Diet High in Sodium} + \dots}{\text{Total Population}}
}
$$

This approach assumes that higher values in the aggregated health and environmental factors correspond to increased mortality risks. Dividing by the population yields a per capita measure, allowing us to compare mortality risks between countries with different population sizes.

```{r mortality-proxy, cache=TRUE}
# Define the health-related variables to include in the Mortality Proxy
health_vars <- c(
  "Outdoor.air.pollution",
  "High.systolic.blood.pressure",
  "Diet.high.in.sodium",
  "Alochol.use",
  "Diet.low.in.whole.grains",
  "Diet.low.in.fruits",
  "Unsafe.water.source",
  "Secondhand.smoke",
  "Low.birth.weight",
  "Child.wasting",
  "Unsafe.sex",
  "Diet.low.in.nuts.and.seeds",
  "Household.air.pollution.from.solid.fuels",
  "Diet.low.in.Vegetables",
  "Low.physical.activity",
  "Smoking",
  "High.fasting.plasma.glucose",
  "Air.pollution",
  "High.body.mass.index",
  "Unsafe.sanitation",
  "No.access.to.handwashing.facility",
  "Drug.use",
  "Low.bone.mineral.density",
  "Vitamin.A.deficiency",
  "Child.stunting",
  "Discontinued.breastfeeding",
  "Non.exclusive.breastfeeding",
  "Iron.deficiency"
)

# Check if all health-related variables are present in merged_df
missing_vars <- setdiff(health_vars, colnames(merged_df))
if(length(missing_vars) > 0){
  stop("The following health-related variables are missing in merged_df: ", paste(missing_vars, collapse = ", "))
}

# Calculate the Mortality Proxy
merged_df <- merged_df %>%
  mutate(
    Mortality_Proxy = rowSums(select(., all_of(health_vars)), na.rm = TRUE) / Population
  )

# Display the first few rows to verify the calculation
head(merged_df %>% select(Code, Year, Mortality_Proxy))
```

**c. Defining Binary Classes**:

With the Mortality Proxy calculated, we categorize each country-year observation into two classes: **High Mortality Rate** and **Low Mortality Rate**. This binary classification simplifies the predictive modeling process.

- **High Mortality Rate**: Countries with Mortality Proxy values **above or equal to** the 75th percentile of the distribution.
- **Low Mortality Rate**: Countries with Mortality Proxy values **below** the 75th percentile of the distribution.

This approach ensures that the top 25% of observations are identified as high-risk, providing a balanced foundation for classification algorithms.

```{r binary-classes, cache=TRUE}
# Calculate the 75th percentile threshold for Mortality Proxy
threshold <- quantile(merged_df$Mortality_Proxy, 0.75, na.rm = TRUE)

# Define binary classes based on the threshold
merged_df <- merged_df %>%
  mutate(
    Mortality_Class = if_else(
      Mortality_Proxy >= threshold,
      "High Mortality Rate",
      "Low Mortality Rate"
    )
  )

# Verify the distribution of the binary classes
class_distribution <- table(merged_df$Mortality_Class)
print(class_distribution)

# Visualize the distribution of Mortality Classes
ggplot(merged_df, aes(x = Mortality_Class, fill = Mortality_Class)) +
  geom_bar() +
  labs(
    title = "Distribution of Mortality Classes",
    x = "Mortality Class",
    y = "Count"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("High Mortality Rate" = "tomato", "Low Mortality Rate" = "skyblue")) +
  theme(legend.position = "none")
```

### **2.2.2. Feature Variables**

We select and prepare relevant feature variables to predict the mortality classes. Proper feature selection enhances model performance, reduces complexity, and mitigates the risk of overfitting. We'll perform univariate analyses to assess each variable's predictive power and check for multicollinearity to remove highly correlated variables.

**a. Initial Feature Selection**:

We begin by selecting health-related and socioeconomic variables likely to influence mortality rates. Unique identifiers and non-numeric variables are excluded to maintain the integrity of the models.

```{r feature-select, cache=TRUE}
# Define the list of health-related variables
health_vars <- c(
  "Outdoor.air.pollution",
  "High.systolic.blood.pressure",
  "Diet.high.in.sodium",
  "Smoking",
  "High.fasting.plasma.glucose",
  "High.body.mass.index",
  "Low.physical.activity",
  "Alochol.use",
  "Diet.low.in.fruits",
  "Diet.low.in.whole.grains"
)

# Socioeconomic variables
socioeconomic_vars <- c(
  "Population",
  "GDP_per_Capita"
)

# Combine all feature variables
feature_vars <- c(health_vars, socioeconomic_vars)

# Create the initial dataset for modeling by selecting the necessary columns
model_df <- merged_df %>%
  select(all_of(feature_vars), Mortality_Class)

# Ensure Mortality_Class is a factor with correct levels
model_df$Mortality_Class <- factor(model_df$Mortality_Class, levels = c("Low Mortality Rate", "High Mortality Rate"))

# Remove any rows with missing values
model_df <- model_df %>% drop_na()

# Inspect the first few rows of the prepared dataset
head(model_df)
```

**b. Univariate Analysis**:

We perform univariate logistic regression for each predictor to assess its individual predictive power.

```{r univariate-regression, cache=TRUE}
# Initialize a dataframe to store AUC values
univariate_results <- data.frame(Predictor = character(), AUC = numeric(), stringsAsFactors = FALSE)

# List of predictor variables
predictors <- names(model_df)[names(model_df) != "Mortality_Class"]

# Loop through each predictor
for (pred in predictors) {
  formula <- as.formula(paste("Mortality_Class ~", pred))
  model <- glm(formula, data = model_df, family = binomial)
  prob <- predict(model, type = "response")
  roc_curve <- roc(model_df$Mortality_Class, prob, levels = c("Low Mortality Rate", "High Mortality Rate"))
  auc_value <- as.numeric(auc(roc_curve))
  univariate_results <- rbind(univariate_results, data.frame(Predictor = pred, AUC = auc_value))
}

# Sort predictors by AUC
univariate_results <- univariate_results[order(-univariate_results$AUC), ]
print(univariate_results)
```

**Interpretation of Results:**

**GDP_per_Capita** has the highest AUC (0.7770), indicating it has the best individual predictive power among the variables tested. **Diet.low.in.fruits** and **Alochol.use** have moderate AUC values (around 0.66â€“0.67), suggesting some predictive ability. The remaining variables have lower AUC values (below 0.65), indicating limited individual predictive power.

Based on the univariate analysis, we'll use the following variables for the multivariate models:

- **GDP_per_Capita**
- **Diet.low.in.fruits**
- **Alochol.use**
- **Diet.high.in.sodium**
- **High.systolic.blood.pressure**
- **Smoking**

**c. Checking for Multicollinearity**:

We will check for multicollinearity among the selected predictors to identify any highly correlated variables that could negatively affect our models.

**Correlation Matrix Analysis**

We calculated the correlation matrix for the selected variables:

- **GDP_per_Capita**
- **Diet.low.in.fruits**
- **Alochol.use**
- **Diet.high.in.sodium**
- **High.systolic.blood.pressure**
- **Smoking**

```{r corr-matrix, cache=TRUE}
# Subset the data to include only the selected predictors
selected_vars <- c(
  "GDP_per_Capita",
  "Diet.low.in.fruits",
  "Alochol.use",
  "Diet.high.in.sodium",
  "High.systolic.blood.pressure",
  "Smoking"
)

# Create a new dataframe with selected predictors
model_df_selected <- model_df %>% select(all_of(selected_vars), Mortality_Class)

# Calculate the correlation matrix
numeric_vars <- model_df_selected %>% select(-Mortality_Class)
corr_matrix <- cor(numeric_vars, use = "complete.obs")

# Display the correlation matrix
print(corr_matrix)

# Plot the correlation matrix
corrplot(corr_matrix, method = "color", addCoef.col = "black", number.cex = 0.7,
         tl.cex = 0.8, tl.col = "black", title = "Correlation Matrix of Selected Predictors",
         mar = c(0, 0, 1, 0))

```

Table: Correlation Matrix of Selected Predictors

| Predictor                        | GDP_per_Capita | Diet.low.in.fruits | Alochol.use | Diet.high.in.sodium | High.systolic.blood.pressure | Smoking |
| -------------------------------- | -------------- | ------------------ | ----------- | ------------------- | ---------------------------- | ------- |
| **GDP_per_Capita**               | 1.00           | -0.21              | -0.16       | -0.19               | -0.13                        | -0.02   |
| **Diet.low.in.fruits**           | -0.21          | 1.00               | 0.56        | 0.71                | 0.85                         | 0.72    |
| **Alochol.use**                  | -0.16          | 0.56               | 1.00        | 0.64                | 0.69                         | 0.58    |
| **Diet.high.in.sodium**          | -0.19          | 0.71               | 0.64        | 1.00                | 0.78                         | 0.72    |
| **High.systolic.blood.pressure** | -0.13          | 0.85               | 0.69        | 0.78                | 1.00                         | 0.88    |
| **Smoking**                      | -0.02          | 0.72               | 0.58        | 0.72                | 0.88                         | 1.00    |

**Interpretation of Results:**

High.systolic.blood.pressure is highly correlated with:

  - **Smoking** (0.88)
  - **Diet.low.in.fruits** (0.85)
  - **Diet.high.in.sodium** (0.78)

Smoking is also highly correlated with:

  - **Diet.low.in.fruits** (0.72)
  - **Diet.high.in.sodium** (0.72)

Due to high multicollinearity, we decided to remove **High.systolic.blood.pressure** and **Smoking** from the predictor set. We retained **Diet.low.in.fruits**, **Alochol.use**, and **Diet.high.in.sodium** as they have acceptable correlations after variable removal.

The final set of predictors is:

- **GDP_per_Capita**
- **Diet.low.in.fruits**
- **Alochol.use**
- **Diet.high.in.sodium**

After removing the highly correlated variables, we recalculated the correlation matrix to confirm that multicollinearity concerns were addressed.

```{r re-corr-matrix, cache=TRUE}
# Final list of predictors
final_vars <- c(
  "GDP_per_Capita",
  "Diet.low.in.fruits",
  "Alochol.use",
  "Diet.high.in.sodium"
)

# Create the final modeling dataset
model_df_final <- model_df %>% select(all_of(final_vars), Mortality_Class)

# Calculate the correlation matrix
numeric_vars_final <- model_df_final %>% select(-Mortality_Class)
corr_matrix_final <- cor(numeric_vars_final, use = "complete.obs")

# Display the correlation matrix
print(corr_matrix_final)
```

**Table: Updated Correlation Matrix**

| Predictor               | GDP_per_Capita | Diet.low.in.fruits | Alochol.use | Diet.high.in.sodium |
| ----------------------- | -------------- | ------------------ | ----------- | ------------------- |
| **GDP_per_Capita**      | 1.00           | -0.21              | -0.16       | -0.19               |
| **Diet.low.in.fruits**  | -0.21          | 1.00               | 0.56        | 0.71                |
| **Alochol.use**         | -0.16          | 0.56               | 1.00        | 0.64                |
| **Diet.high.in.sodium** | -0.19          | 0.71               | 0.64        | 1.00                |

**Interpretation of Results:**

The highest correlation is between **Diet.low.in.fruits** and **Diet.high.in.sodium** (0.71), which is below the threshold of 0.8. Other correlations are moderate to low, indicating that multicollinearity is not a significant concern with these variables.

**Variance Inflation Factor (VIF) Analysis**

We calculated the VIF values for the updated predictors to further assess multicollinearity.

```{r vif, cache=TRUE}
# Fit a logistic regression model with the final predictors
vif_model_final <- glm(Mortality_Class ~ ., data = model_df_final, family = binomial)

# Calculate VIF values
vif_values_final <- vif(vif_model_final)
print(vif_values_final)
```

**Table: VIF Values of Final Predictors**

| Predictor           | VIF  |
| ------------------- | ---- |
| GDP_per_Capita      | 1.05 |
| Diet.low.in.fruits  | 2.01 |
| Alochol.use         | 1.64 |
| Diet.high.in.sodium | 2.30 |

**Interpretation of Results:**

All VIF values are below 5, suggesting that multicollinearity is within acceptable limits. This confirms that our final set of predictors is suitable for modeling without multicollinearity issues.

By analyzing the correlation matrix and VIF values, we refined our predictor set to include variables that contribute uniquely to the model:

- **GDP_per_Capita**
- **Diet.low.in.fruits**
- **Alochol.use**
- **Diet.high.in.sodium**

This refined set of predictors enhances the reliability and interpretability of our models, allowing us to proceed confidently to the modeling phase.

**d. Final Feature Variables**:

Based on the univariate analysis and multicollinearity checks, we refined our feature variables to enhance model performance and interpretability:

- **GDP_per_Capita**
- **Diet.low.in.fruits**
- **Alochol.use**
- **Diet.high.in.sodium**

```{r update-dataset, cache=TRUE}
# Final list of predictors including the response variable
final_vars <- c(
  "GDP_per_Capita",
  "Diet.low.in.fruits",
  "Alochol.use",
  "Diet.high.in.sodium",
  "Mortality_Class"  # This is our response variable
)

# Update the modeling dataset
model_df <- model_df %>% select(all_of(final_vars))

# Ensure Mortality_Class is a factor with correct levels
model_df$Mortality_Class <- factor(model_df$Mortality_Class, levels = c("Low Mortality Rate", "High Mortality Rate"))

# Verify that there are no missing values
sum(is.na(model_df))  # Should be 0 if data is clean

# Inspect the structure of the final dataset
str(model_df)
```

## **2.3. Null Model**

A **Null Model** serves as a baseline to evaluate the performance of more complex classification models. In this context, the null model predicts the most frequent class for all observations, disregarding any input features. This provides a reference point to determine whether the predictive models offer a meaningful improvement over random or simplistic guessing.

Given the distribution of our binary classes:

- **High Mortality Rate**: 947 observations
- **Low Mortality Rate**: 2,838 observations

The null model will predict **"Low Mortality Rate"** for every country-year observation since it is the majority class.

```{r null-model, cache=TRUE}
# Calculate the distribution of the binary classes
class_distribution <- table(model_df$Mortality_Class)
print(class_distribution)

# Determine the most frequent class
most_frequent_class <- names(which.max(class_distribution))
print(paste("Most Frequent Class:", most_frequent_class))

# Create predictions based on the null model
null_predictions <- rep(most_frequent_class, nrow(model_df))

# Calculate Accuracy of the Null Model
null_accuracy <- mean(null_predictions == model_df$Mortality_Class)
print(paste("Null Model Accuracy:", round(null_accuracy * 100, 2), "%"))

# Generate a Confusion Matrix for the Null Model
confusion_null <- confusionMatrix(
  factor(null_predictions, levels = levels(model_df$Mortality_Class)),
  model_df$Mortality_Class
)

print(confusion_null)
```

**Interpretation of Results:**

- **Accuracy:** The null model achieves an accuracy of **74.98%**, which corresponds to the proportion of the majority class (**Low Mortality Rate**). This means that without considering any features, simply predicting the most frequent class yields an accuracy of approximately **74.98%**.
- **Confusion Matrix Insights:**
  - **True Positives** (High Mortality Rate predicted as High): 0
  - **False Negatives** (High Mortality Rate predicted as Low): 947
  - **True Negatives** (Low Mortality Rate predicted as Low): 2,838
  - **False Positives** (Low Mortality Rate predicted as High): 0
- **Performance Metrics:**
  - **Sensitivity (Recall) for High Mortality Rate:** 0% (no high mortality rates are correctly predicted)
  - **Specificity for Low Mortality Rate:** 100% (all low mortality rates are correctly predicted)
  - **Kappa:** 0, indicating no agreement beyond chance.
  - **Balanced Accuracy:** 50%, reflecting equal weighting of sensitivity and specificity.

The null model provides a benchmark against which we can assess the effectiveness of our classification models. Any predictive model should aim to outperform this baseline, demonstrating its ability to capture meaningful patterns and relationships within the data. By comparing our models' performance metrics to those of the null model, we can quantify the added value of incorporating health, socioeconomic, and environmental factors into our predictions.

## **2.4. Splitting the Data**

To evaluate the performance of our classification models effectively, it is essential to divide the dataset into separate **training** and **testing** subsets. This separation allows us to train the models on one portion of the data and assess their generalization capabilities on unseen data.

- **Training Set:** Used to build and tune the classification models.
- **Testing Set:** Used to evaluate the models' performance on new, unseen data, ensuring that the models do not overfit and can generalize well.

An **80/20 split** is commonly used, allocating 80% of the data for training and 20% for testing. This ratio provides a substantial amount of data for model training while retaining enough observations to reliably assess model performance.

```{r split-data, cache=TRUE}
# Set seed for reproducibility
set.seed(123)

# Create a partition index for 80% training data
train_index <- createDataPartition(model_df$Mortality_Class, p = 0.8, list = FALSE)

# Split the data into training and testing sets
train_data <- model_df[train_index, ]
test_data  <- model_df[-train_index, ]

# Verify the distribution of classes in training and testing sets
train_distribution <- table(train_data$Mortality_Class)
test_distribution  <- table(test_data$Mortality_Class)

print("Training Set Class Distribution:")
print(train_distribution)

print("Testing Set Class Distribution:")
print(test_distribution)

# Visualize the class distribution in training and testing sets

# Combine distributions into a single dataframe for plotting
distribution_df <- data.frame(
  Class = rep(names(train_distribution), 2),
  Count = c(train_distribution, test_distribution),
  Set = rep(c("Training", "Testing"), each = length(train_distribution))
)

ggplot(distribution_df, aes(x = Class, y = Count, fill = Set)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Class Distribution in Training and Testing Sets",
    x = "Mortality Class",
    y = "Count"
  ) +
  theme_minimal() +
  scale_fill_manual(values = c("Training" = "steelblue", "Testing" = "orange")) +
  theme(legend.title = element_blank())
```

The class distribution in both the training and testing sets mirrors the overall distribution of the dataset, maintaining approximately 25% of observations as High Mortality Rate and 75% as Low Mortality Rate. This stratified sampling ensures that both subsets are representative of the entire dataset, facilitating reliable model training and evaluation.

## **2.5. Classification Models**

We develop and evaluate two classification models to predict the **Mortality Class** (**High Mortality Rate** vs. **Low Mortality Rate**) for each country-year observation. The chosen models are:

1. **Decision Tree Classifier**
2. **Logistic Regression Classifier**

These models are selected for their interpretability and effectiveness in binary classification tasks.

### **2.5.1. Decision Tree Classifier**

Decision Trees are intuitive models that split the data based on feature values to create decision rules leading to the target class. They are easy to visualize and interpret, making them suitable for understanding the factors influencing mortality rates.

```{r classifier-decision-tree, fig.width=10, fig.height=10, cache=TRUE}
# Ensure that Mortality_Class is a factor in both train and test datasets
train_data$Mortality_Class <- factor(train_data$Mortality_Class, levels = c("Low Mortality Rate", "High Mortality Rate"))
test_data$Mortality_Class <- factor(test_data$Mortality_Class, levels = c("Low Mortality Rate", "High Mortality Rate"))

# Train the Decision Tree model
tree_model <- rpart(
  Mortality_Class ~ ., 
  data = train_data, 
  method = "class",
  control = rpart.control(cp = 0.01)  # cp is the complexity parameter
)

# Visualize the Decision Tree
rpart.plot(tree_model, type = 2, extra = 104, fallen.leaves = TRUE, main = "Decision Tree for Mortality Classification", cex = 0.3)

# Predict on the testing set
tree_predictions <- predict(tree_model, newdata = test_data, type = "class")

# Convert predictions to factor with the same levels as Mortality_Class
tree_predictions <- factor(tree_predictions, levels = levels(test_data$Mortality_Class))

# Generate Confusion Matrix
confusion_tree <- confusionMatrix(tree_predictions, test_data$Mortality_Class)
print(confusion_tree)

# Calculate ROC and AUC for Decision Tree
tree_prob <- predict(tree_model, newdata = test_data, type = "prob")[,2]
roc_tree <- roc(response = test_data$Mortality_Class,
                predictor = tree_prob,
                levels = c("Low Mortality Rate", "High Mortality Rate"))

# Plot ROC Curve
plot(roc_tree, col = "blue", main = "ROC Curve - Decision Tree")
abline(a=0, b=1, lty=2, col="gray")

# Display AUC
auc_tree <- auc(roc_tree)
print(paste("Decision Tree AUC:", round(auc_tree, 4)))
```

**Interpretation of Results:**

- **Accuracy:** The decision tree model achieved an accuracy of **85.05%**, correctly predicting the mortality class for a significant portion of the test set.
- **Sensitivity (Recall for Low Mortality Rate):** The model accurately identified **90.65%** of the countries with a low mortality rate, demonstrating strong ability in detecting the majority class.
- **Specificity (Recall for High Mortality Rate):** It correctly identified **68.25%** of the countries with a high mortality rate, which is a considerable improvement over random guessing.
- **Positive Predictive Value (Precision for Low Mortality Rate):** When the model predicted a low mortality rate, it was correct **89.55%** of the time.
- **Negative Predictive Value (Precision for High Mortality Rate):** When predicting a high mortality rate, the model was correct **70.88%** of the time.
- **Kappa Statistic:** A value of **0.5964** indicates a moderate to substantial agreement between the predicted and actual classes beyond chance.
- **Area Under the ROC Curve (AUC):** An AUC of **0.8479** suggests the model has excellent ability to distinguish between high and low mortality rate classes.

**Confusion Matrix Insights:**

- **True Positives (Low Mortality Rate correctly identified):** **514** countries.
- **True Negatives (High Mortality Rate correctly identified):** **129** countries.
- **False Positives (High Mortality Rate incorrectly predicted as Low):** **60** countries.
- **False Negatives (Low Mortality Rate incorrectly predicted as High):** **53** countries.

**Overall Assessment:**

The decision tree model performs well in classifying countries into low and high mortality rate categories. It shows a strong balance between sensitivity and specificity, and the high AUC value indicates reliable discriminative power. The model's performance is significantly better than the null model, highlighting its effectiveness.

### **2.5.2. Logistic Regression Classifier**

Logistic Regression is a probabilistic model suitable for binary classification tasks. It estimates the probability that a given input point belongs to a particular class, making it effective for understanding the relationship between features and the target variable.

```{r classifier-logistic-regression, cache=TRUE}
# Ensure Mortality_Class is a factor with correct levels
train_data$Mortality_Class <- factor(train_data$Mortality_Class, levels = c("Low Mortality Rate", "High Mortality Rate"))
test_data$Mortality_Class <- factor(test_data$Mortality_Class, levels = c("Low Mortality Rate", "High Mortality Rate"))

# Train the Logistic Regression model
logistic_model <- glm(
  Mortality_Class ~ ., 
  data = train_data, 
  family = binomial
)

# Predict probabilities on the testing set
logistic_prob <- predict(logistic_model, newdata = test_data, type = "response")

# Convert probabilities to class labels using 0.5 as threshold
logistic_predictions <- ifelse(logistic_prob >= 0.5, "High Mortality Rate", "Low Mortality Rate")
logistic_predictions <- factor(logistic_predictions, levels = levels(test_data$Mortality_Class))

# Generate Confusion Matrix
confusion_logistic <- confusionMatrix(logistic_predictions, test_data$Mortality_Class)
print(confusion_logistic)

# Calculate ROC and AUC
roc_logistic <- roc(response = test_data$Mortality_Class, predictor = logistic_prob, levels = c("Low Mortality Rate", "High Mortality Rate"))

# Plot ROC Curve
plot(roc_logistic, col = "red", main = "ROC Curve - Logistic Regression")
abline(a=0, b=1, lty=2, col="gray")

# Display AUC
auc_logistic <- auc(roc_logistic)
print(paste("Logistic Regression AUC:", round(auc_logistic, 4)))
```

**Interpretation of Results:**

- **Accuracy:** The logistic regression model achieved an accuracy of **72.22%**, which is slightly lower than the decision tree model and close to the no-information rate (the proportion of the majority class, 75%).
- **Sensitivity (Recall for Low Mortality Rate):** The model correctly identified **95.06%** of the countries with a low mortality rate, indicating a high ability to detect the majority class.
- **Specificity (Recall for High Mortality Rate):** It only correctly identified **3.70%** of the countries with a high mortality rate, showing poor performance in detecting the minority class.
- **Positive Predictive Value (Precision for Low Mortality Rate):** When the model predicted a low mortality rate, it was correct **74.76%** of the time.
- **Negative Predictive Value (Precision for High Mortality Rate):** When predicting a high mortality rate, the model was correct **20.00%** of the time.
- **Kappa Statistic:** A value of **-0.0169** suggests no agreement between the predicted and actual classes beyond chance, indicating poor model performance.
- **Area Under the ROC Curve (AUC):** An AUC of **0.7063** indicates acceptable but not strong ability to distinguish between the classes.

**Confusion Matrix Insights:**

- **True Positives (Low Mortality Rate correctly identified):** **539** countries.
- **True Negatives (High Mortality Rate correctly identified):** **7** countries.
- **False Positives (High Mortality Rate incorrectly predicted as Low):** **182** countries.
- **False Negatives (Low Mortality Rate incorrectly predicted as High):** **28** countries.

**Overall Assessment:**

The logistic regression model demonstrates a high sensitivity for detecting countries with a low mortality rate but struggles to accurately identify countries with a high mortality rate, as evidenced by the low specificity and negative predictive value. The negative Kappa statistic suggests that the model's predictions are not better than random chance when accounting for class imbalance. The modest AUC value indicates that the model's ability to discriminate between the two classes is acceptable but not strong.

## **2.6. Model Evaluation**

We compare the performance of the Decision Tree and Logistic Regression classifiers using the refined feature set derived from our earlier analyses. We evaluate each model based on key metrics such as accuracy, sensitivity, specificity, Kappa statistic, and the Area Under the Receiver Operating Characteristic Curve (AUC). We also discuss how feature selection impacted the models.

**Decision Tree Classifier Performance:**

The Decision Tree model achieved an accuracy of **85.05%**, correctly classifying a significant portion of the test data. It demonstrated a high sensitivity of **90.65%** for the 'Low Mortality Rate' class, indicating strong ability to identify countries with low mortality rates. The specificity was **68.25%** for the 'High Mortality Rate' class, showing effective recognition of countries with high mortality rates. The Kappa statistic of **0.5964** suggests moderate to substantial agreement between the predicted and actual classes beyond chance. An AUC of **0.8479** indicates excellent discriminative ability in distinguishing between the two mortality classes.

**Logistic Regression Classifier Performance:**

The Logistic Regression model obtained an accuracy of **72.22%**, which is lower than the Decision Tree and close to the baseline accuracy of predicting the majority class. It showed high sensitivity of **95.06%** for the 'Low Mortality Rate' class but very low specificity of **3.70%** for the 'High Mortality Rate' class, reflecting difficulty in detecting the minority class. The negative Kappa statistic of **-0.0169** suggests no better agreement than random chance. The AUC was **0.7063**, indicating acceptable but limited discriminative ability.

**Comparison and Discussion:**

The Decision Tree classifier outperforms the Logistic Regression classifier across most evaluation metrics. Its higher specificity and balanced sensitivity make it better suited for handling the class imbalance in our dataset. The Logistic Regression model's tendency to predict the majority class highlights its limitations in this context, as evidenced by its low specificity and negative Kappa statistic.

**Impact of Feature Selection:**

Our feature selection processâ€”focusing on univariate analysis and multicollinearity checksâ€”resulted in a refined set of predictors: **GDP_per_Capita**, **Diet.low.in.fruits**, **Alochol.use**, and **Diet.high.in.sodium**. This careful selection enhanced the Decision Tree model's performance by ensuring that only variables with strong predictive power and minimal redundancy were included. The Logistic Regression model, however, did not achieve comparable performance with these features, suggesting that it may be less suitable for this classification task under the current conditions.

**Overall Assessment:**

Based on the evaluation metrics and comparative analysis, the Decision Tree classifier demonstrates superior performance in classifying countries by mortality rate using the selected features. Its ability to balance sensitivity and specificity, along with a higher AUC, underscores its suitability for this task. The Logistic Regression classifier, while showing high sensitivity for the 'Low Mortality Rate' class, had limitations in detecting the 'High Mortality Rate' class. This suggests that, in this context, the Decision Tree model is more effective for our classification objectives using the selected features.

## **2.7. Using LIME for Model Interpretation**

We apply the Local Interpretable Model-agnostic Explanations (LIME) technique to interpret the predictions made by our Decision Tree classifier. LIME helps us understand the contribution of each feature to a particular prediction, offering insights into the model's decision-making process for individual instances.

```{r lime, cache=TRUE}
# Define 'model_type' and 'predict_model' methods for 'rpart' models
model_type.rpart <- function(x, ...) {
  if (x$method == "class") "classification" else "regression"
}

predict_model.rpart <- function(x, newdata, type, ...) {
  if (type == "raw") {
    preds <- predict(x, newdata, type = "class")
    data.frame(Response = preds)
  } else if (type == "prob") {
    preds <- predict(x, newdata, type = "prob")
    as.data.frame(preds)
  } else {
    stop("Invalid prediction type")
  }
}

# Create the explainer using the training data
explainer <- lime(
  x = train_data[, -which(names(train_data) == "Mortality_Class")],
  model = tree_model,
  bin_continuous = TRUE
)

# Select a few instances from the test set for explanation
set.seed(123)
instances_to_explain <- test_data[sample(1:nrow(test_data), 3), ]

# Generate explanations using LIME
explanation <- explain(
  x = instances_to_explain[, -which(names(instances_to_explain) == "Mortality_Class")],
  explainer = explainer,
  n_features = 4,
  n_labels = 1
)

# Visualize the explanations
plot_features(explanation) +
  labs(title = "LIME Explanations for Decision Tree Predictions")
```

**Interpretation of Results:**

For each instance, LIME provided the predicted label, prediction probability, explanation fit, and the key features influencing the prediction. Below is a summary of the findings for the three instances:

**Instance 1 (Case 2082)**

The model predicted a **Low Mortality Rate** with a probability of **97%**. The features that most strongly supported this prediction were low levels of **Vitamin A deficiency**, **unsafe sex**, and **smoking**. These factors are associated with better health outcomes and lower mortality risks. However, the population size, which fell between 414,508 and 2,650,930, contradicted the prediction to some extent, possibly indicating that certain risks are associated with moderate population sizes in the model's assessment.

**Instance 2 (Case 2328)**

For this instance, the model predicted a **Low Mortality Rate** with a probability of **99%**. The prediction was supported by moderate levels of **unsafe sex** and low **Vitamin A deficiency**, indicating relatively good health practices and nutrition. On the other hand, a diet low in nuts and seeds, and a population size in the same moderate range as before, contradicted the prediction, suggesting these factors might increase mortality risk.

**Instance 3 (Case 897)**

The model again predicted a **Low Mortality Rate**, with a probability of **97%**. Supporting features included very low **Vitamin A deficiency** and low levels of **unsafe sex**, both indicative of favorable health conditions. Contradicting the prediction were low **bone mineral density** and a smaller population size (less than 414,508), which the model may associate with increased mortality risks due to factors like limited healthcare resources.

**Discussion**

Across all three instances, low levels of **Vitamin A deficiency** and **unsafe sex** consistently supported the predictions of a low mortality rate. These findings align with established knowledge that adequate nutrition and safe sexual practices contribute to better health outcomes. The contradictions posed by factors such as **population size**, **diet low in nuts and seeds**, and **low bone mineral density** highlight areas where the model identifies potential risks. However, the positive influences outweighed the negatives in these cases, leading to high-confidence predictions of low mortality rates.

**Overall Assessment**

The LIME analysis provided valuable insights into how the Decision Tree classifier makes predictions. It confirmed that the model relies on meaningful health indicators that are logically associated with mortality rates. This interpretability enhances our confidence in the model's reliability and its applicability for understanding facto
rs affecting mortality in different countries.

# **Section 3: Clustering**
This section will involve performing clustering analysis to discover patterns in the data.

## **3.1. Selecting Feature Variables for Clustering**

To begin, we need to choose a set of feature variables for the clustering analysis. We will use the same refined set of predictors from the classification task to maintain consistency and leverage the features we've already identified as significant:

- **GDP_per_Capita**
- **Diet.low.in.fruits**
- **Alochol.use**
- **Diet.high.in.sodium**

These variables capture economic and dietary factors that are likely to influence mortality rates and may reveal interesting clusters among countries.

```{r}
# Prepare the data for clustering
clustering_df <- model_df %>% select(-Mortality_Class)
```

## **3.2. Data Preprocessing for Clustering**

Before applying clustering algorithms, it is essential to preprocess the data to ensure that all features contribute equally to the analysis. Clustering algorithms are sensitive to the scale of variables; hence, standardizing the data is a crucial step.

**Standardize the Variables:** Standardization transforms the data to have a mean of zero and a standard deviation of one. This process ensures that each feature has equal weight in the clustering process, preventing features with larger scales from dominating the distance calculations.

```{r cluster-scale, cache=TRUE}
# Standardize the data
clustering_data <- scale(clustering_df)
```

After standardization, each feature has been transformed to have a mean of zero and a standard deviation of one. This ensures that all features contribute equally to the clustering process, preventing variables with larger scales from dominating the distance calculations.

## **3.3. Choosing a Distance Measure**

For our clustering analysis, we selected **Euclidean distance** as the distance metric. Euclidean distance is well-suited for continuous numerical data and aligns seamlessly with the K-means clustering algorithm. By measuring the straight-line distance between data points in the feature space, Euclidean distance provides an intuitive and straightforward assessment of similarity.

**Reasoning:**

- **Interpretability:** Euclidean distance offers a clear and easily understandable metric for evaluating how similar or dissimilar two countries are based on their economic and dietary features.
- **Compatibility with K-means:** K-means clustering aims to minimize the within-cluster sum of squares, which directly corresponds to the use of Euclidean distance. This ensures that the algorithm efficiently groups countries with similar standardized feature values into distinct clusters.

## **3.4. Determining the Optimal Number of Clusters (k)**

Selecting the appropriate number of clusters is crucial. We employ the following methods to determine the optimal k:

- **Elbow Method**
- **Silhouette Analysis**
- **Gap Statistic**

### **3.4.1. Elbow Method**

Selecting the optimal number of clusters (**k**) is essential for effective clustering analysis. The **Elbow Method** assists in determining the appropriate **k** by evaluating the total within-cluster sum of squares (WSS) for different values of **k** and identifying the point where the rate of decrease sharply changes, resembling an "elbow."

```{r cluster-elbow, cache=TRUE}
# Elbow method
fviz_nbclust(clustering_data, kmeans, method = "wss") +
  labs(title = "Elbow Method for Determining Optimal k")
```

- Elbow Point at k = 4:
The plot exhibits a noticeable "elbow" around **k = 4**. Before **k = 4**, adding more clusters significantly reduces WSS, indicating substantial improvements in cluster compactness. Beyond **k = 4**, the rate of WSS reduction slows down, suggesting diminishing returns in clustering performance.

Based on the Elbow Method, we determined that **4 clusters** is the optimal number for our dataset. This choice balances the complexity of the model with the effectiveness of clustering, ensuring that the clusters are well-defined without introducing unnecessary complexity.

### **3.4.2. Silhouette Analysis**

To further validate the optimal number of clusters, we employed the **Silhouette Analysis**. This method evaluates how similar each data point is to its own cluster compared to other clusters, providing a measure of cluster quality. 

We calculated the average silhouette width for different values of **k**:

```{r cluster-silhouette, cache=TRUE}
# Silhouette analysis
fviz_nbclust(clustering_data, kmeans, method = "silhouette") +
  labs(title = "Silhouette Analysis for Determining Optimal k")
```

- Peak at k = 2:
The highest average silhouette width occurs at **k = 2**, with a value of approximately **0.5**. This indicates that two clusters provide the best separation and cohesion, with data points being well-assigned to their respective clusters.
- Decline After k = 2:
After **k = 2**, the average silhouette width slightly decreases and stabilizes. This suggests that adding more clusters beyond two does not significantly enhance the clustering quality, as the improvement in silhouette width is minimal.

The Silhouette Analysis corroborates the findings from the Elbow Method, reinforcing that **k = 2** is the optimal number of clusters for our dataset. This choice ensures that the clusters are both well-separated and cohesive, capturing the most meaningful groupings without unnecessary complexity.

### **3.4.3. Gap Statistic**

To further validate the optimal number of clusters (**k**) identified by the Elbow Method and Silhouette Analysis, we utilized the **Gap Statistic**. This method compares the total within-cluster variation to that expected under a reference null distribution, providing a robust criterion for selecting **k**.

We setted k.max = 10 to evaluate up to ten clusters and B = 50 for bootstrap sampling to ensure reliability:

```{r cluster-gap, cache=TRUE}
# Gap statistic
set.seed(123)
gap_stat <- clusGap(clustering_data, FUN = kmeans, nstart = 25, K.max = 10, B = 50)
fviz_gap_stat(gap_stat) +
  labs(title = "Gap Statistic for Determining Optimal k")
```

- Peak at k = 4:
The Gap Statistic plot reveals a significant increase in the gap value at **k = 4**, suggesting that four clusters provide a notably better fit compared to fewer clusters.
- Diminishing Returns Beyond k = 4:
Although the gap statistic continues to increase beyond **k = 4**, the rate of improvement slows down. This indicates that adding more clusters does not substantially enhance clustering quality, as evidenced by the plateauing of gap values.

The Gap Statistic analysis indicates that **k = 4** is the optimal number of clusters for our dataset. This choice is supported by the significant peak at **k = 4**, where the gap statistic suggests a meaningful improvement in cluster separation and cohesion. Beyond this point, additional clusters yield diminishing returns, affirming that four clusters effectively capture the inherent groupings in the data without unnecessary complexity.

### **3.4.4. Optimal Number of Clusters (k)**

Selecting the appropriate number of clusters (**k**) is pivotal for effective clustering analysis. We utilized three distinct methods to determine the optimal **k** for our dataset: the **Elbow Method**, **Silhouette Analysis**, and the **Gap Statistic**.

Considering the results from all three methods:

- **Elbow Method:** Suggested **k = 4**
- **Silhouette Analysis:** Suggested **k = 2**
- **Gap Statistic:** Suggested **k = 4**

To balance these findings, we determine that **k = 3** is the optimal number of clusters for our dataset. This choice serves as a compromise between the Elbow and Gap Statistic methods, which both indicate **k = 4**, and the Silhouette Analysis, which suggests **k = 2**. Selecting **k = 3** allows us to capture meaningful groupings within the data without overcomplicating the model, ensuring that the clusters are both distinct and representative of underlying patterns.

## **3.5. Applying K-means Clustering**

With the optimal number of clusters (**k = 3**) determined through the Elbow Method, Silhouette Analysis, and Gap Statistic, we proceed to apply the K-means clustering algorithm to our standardized dataset. K-means is an unsupervised learning algorithm that partitions data into **k** distinct, non-overlapping clusters based on feature similarities.

```{r cluster-kmeans, cache=TRUE}
# Apply K-means clustering with k = 3
set.seed(123)
kmeans_result <- kmeans(clustering_data, centers = 3, nstart = 25)

# View the cluster assignments
head(kmeans_result$cluster)

# View the cluster centers
print(kmeans_result$centers)

# View the size of each cluster
print(kmeans_result$size)

# Total within-cluster sum of squares
print(kmeans_result$tot.withinss)

```

**Interpretation of Results:**

- **Cluster 1 (1010 Countries):**
  - **GDP_per_Capita:** Below average
  - **Diet.low.in.fruits, Alochol.use, Diet.high.in.sodium:** Significantly above average
This cluster represents countries with lower economic status and poorer dietary habits. High levels of low fruit consumption, alcohol use, and sodium intake indicate challenges in nutritional and health-related behaviors.

- **Cluster 2 (273 Countries):**
  - **GDP_per_Capita:** Significantly above average
  - **Diet.low.in.fruits, Alochol.use, Diet.high.in.sodium:** Below average
Countries in this cluster exhibit high economic status coupled with healthier dietary profiles. Lower instances of low fruit consumption, alcohol use, and sodium intake suggest better nutritional and health practices.

- **Cluster 3 (2502 Countries):**
  - **GDP_per_Capita:** Slightly below average
  - **Diet.low.in.fruits, Alochol.use, Diet.high.in.sodium:** Below average
This cluster includes countries with slightly below-average economic status and relatively healthier dietary habits. Similar to Cluster 2, but with lower economic indicators, these countries maintain better nutritional behaviors despite modest economic standings.

The K-means clustering algorithm effectively grouped the countries into three distinct clusters based on their economic and dietary profiles:

1. **Cluster 1:** Low GDP per capita and poor dietary habits.
2. **Cluster 2:** High GDP per capita and healthy dietary habits.
3. **Cluster 3:** Slightly below-average GDP per capita and healthy dietary habits.

These clusters reveal meaningful patterns, highlighting the relationship between economic status and dietary behaviors. **Cluster 2** stands out with its combination of high economic indicators and healthy lifestyles, while **Cluster 1** highlights the challenges faced by lower-income countries in maintaining good dietary practices. **Cluster 3** bridges these groups, showcasing that even with modest economic standings, countries can achieve healthier dietary outcomes.

## **3.6. Visualizing the Clustering Results**

To gain a clearer understanding of the clustering outcomes, we visualized the clusters using **Principal Component Analysis (PCA)**. PCA reduces the dimensionality of the data, transforming the original features into principal components that capture the most variance. By projecting the data onto the first two principal components, we can effectively visualize the clustering results in a two-dimensional space.

```{r cluster-visaul, cache=TRUE}
# Visualize clusters using PCA
fviz_cluster(kmeans_result, data = clustering_data,
             ellipse.type = "convex",
             geom = "point",
             stand = FALSE,
             show.clust.cent = TRUE) +
  labs(title = "K-means Clustering Results (k = 3)") +
  theme_minimal()
```

**Interpretation of Results:**

- **Cluster 1:** Comprises countries with lower GDP per capita and poorer dietary habits, indicated by higher values in **Diet.low.in.fruits**, **Alochol.use**, and **Diet.high.in.sodium**.
- **Cluster 2:** Represents countries with significantly higher GDP per capita and healthier dietary profiles, characterized by lower values in the same dietary features.
- **Cluster 3:** Includes countries with moderate GDP per capita and relatively healthier dietary habits compared to Cluster 1, but not as pronounced as those in Cluster 2.

The PCA-based visualization confirms that **k = 3** effectively captures the underlying patterns in the data, distinguishing a clearly separate group of economically prosperous and health-conscious countries (**Cluster 2**), while grouping countries with similar economic and dietary profiles into **Clusters 1 and 3**. This visualization validates our clustering choice, providing clear insights into the economic and dietary distinctions among the countries analyzed.

## **3.7. Discussing the Impact of Distance Measure**

In our clustering analysis, we utilized **Euclidean distance** as the distance metric. This choice plays a pivotal role in how the clustering algorithm groups the countries based on their feature similarities.

By employing Euclidean distance on our **standardized** dataset, each feature contributes equally to the distance calculations. This means that countries are grouped together based on their overall similarity across all selected featuresâ€”**GDP_per_Capita**, **Diet.low.in.fruits**, **Alochol.use**, and **Diet.high.in.sodium**. The standardization ensures that no single feature dominates the clustering process due to its scale, allowing the algorithm to consider the combined effect of all features uniformly.

As a result, clusters formed using Euclidean distance reflect comprehensive profiles of the countries, capturing both economic and dietary characteristics cohesively. This leads to well-defined and meaningful groupings, as observed in our visualization where distinct clusters emerged based on the integrated feature values.

Choosing Euclidean distance, in conjunction with data standardization, ensured that our clustering algorithm effectively identified groups of countries with similar economic and dietary profiles. This metric facilitated the formation of balanced and interpretable clusters, enhancing our ability to uncover underlying patterns within the data.

## **3.8. Summary of Clustering Results**

In this clustering analysis, we employed the **K-means algorithm** with **k = 3** to group countries based on their economic and dietary profiles. The optimal number of clusters was determined using the Elbow Method, Silhouette Analysis, and Gap Statistic, with the Gap Statistic reinforcing the choice of three clusters.

**Cluster Characteristics:**

- **Cluster 1 (1010 Countries):**
   - **Economic Status:** Below-average GDP per capita.
   - **Dietary Habits:** Higher levels of low fruit consumption, alcohol use, and high sodium intake.
   - **Implications:** Represents countries with lower economic standing and poorer dietary practices, potentially correlating with higher mortality rates.
- **Cluster 2 (273 Countries):**
   - **Economic Status:** Significantly higher GDP per capita.
   - **Dietary Habits:** Lower levels of low fruit consumption, alcohol use, and high sodium intake.
   - **Implications:** Encompasses economically prosperous countries with healthier dietary profiles, likely associated with lower mortality rates.
- **Cluster 3 (2502 Countries):**
   - **Economic Status:** Slightly below-average GDP per capita.
   - **Dietary Habits:** Relatively low levels of low fruit consumption, alcohol use, and high sodium intake.
   - **Implications:** Includes countries with moderate economic status and healthier dietary behaviors compared to Cluster 1, indicating better health outcomes despite modest economic indicators.

**Impact of Distance Measure:**

Utilizing **Euclidean distance** on standardized data ensured that each feature contributed equally to the clustering process. This approach facilitated the formation of cohesive clusters based on overall similarity across economic and dietary factors, resulting in meaningful and interpretable groupings.

**Effectiveness of Clustering:**

The PCA-based visualization confirmed the distinctiveness of the three clusters:

- **Cluster 2** was clearly separated, highlighting its unique combination of high economic status and healthy dietary habits.
- **Clusters 1 and 3** exhibited some overlap, reflecting similarities in their feature profiles but maintaining distinct groupings based on economic and dietary differences.

Overall, the clustering analysis successfully identified three distinct groups of countries, providing valuable insights into how economic and dietary factors interplay to influence mortality rates. These findings underscore the importance of both economic prosperity and healthy dietary practices in shaping health outcomes across different regions.

# **Section 4: Interactive Exploration with Shiny App**

To enhance the exploratory data analysis (EDA) and provide an interactive platform for users to delve deeper into the results, we developed a **Shiny App**. This application facilitates dynamic exploration of single variable performances, comparison of classification models, and visualization of clustering outcomes.

## **4.1. Shiny App Overview**

The Shiny App is designed with a user-friendly interface that organizes various analytical components into intuitive sections. It enables users to interactively explore:

- **Exploratory Data Analysis:** Access to single-variable and multiple-variable visualizations.
- **Single Variable Model Performance:** Assess the impact and performance metrics of individual features.
- **Classification Model Performance:** Compare the performance of the Decision Tree and Logistic Regression classifiers.
- **Clustering Results:** Visualize and interpret the clustering outcomes based on selected features.

## **4.2. Demonstration Video**

A short **2-3 minute video** demonstrates the functionalities of the Shiny App, highlighting its interactive features and how it supports exploratory data analysis. [**Watch the Demonstration Video Here**](#) *(Replace `#` with your actual YouTube link)*

**Note:** The video includes a walkthrough of the app's interface, showcasing how to navigate between tabs, interact with plots, and interpret the results effectively.

# **Conclusion**

This project offered a thorough analysis of the factors influencing mortality rates across various countries by combining health-related metrics from the WHO dataset with economic indicators from the World Bank. One of the key findings is the significant economic impact on health outcomes; higher GDP per Capita is linked to lower mortality rates, underscoring the importance of economic prosperity in enhancing public health. Additionally, elevated levels of outdoor air pollution, high systolic blood pressure, smoking rates, and high sodium intake were found to correlate with increased mortality rates, highlighting the critical role of environmental and lifestyle factors in shaping health outcomes.

In our predictive modeling efforts, we utilized Decision Tree and Logistic Regression classifiers to forecast mortality rates. The Decision Tree model outperformed Logistic Regression, effectively distinguishing between high and low mortality classes with greater accuracy and reliability. Furthermore, through K-means clustering, countries were categorized into distinct groups based on their economic and dietary profiles, revealing patterns that align closely with observed health outcomes.

Based on these insights, several recommendations emerge. Public health policies should focus on implementing targeted interventions to reduce air pollution, promote healthy diets, and curb smoking to lower mortality rates. Strengthening economic growth strategies is also essential, as it lays the foundation for enhancing healthcare infrastructure and access. Additionally, enforcing stricter environmental regulations can mitigate the adverse effects of pollution on public health.

Overall, the findings from this analysis emphasize the interconnectedness of economic status, environmental conditions, and lifestyle choices in determining mortality rates. By leveraging these insights, policymakers and health professionals can develop effective strategies and policies aimed at reducing mortality and improving global health standards.